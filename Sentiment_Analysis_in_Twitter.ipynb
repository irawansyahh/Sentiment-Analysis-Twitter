{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "name": "Sentiment_Analysis_in_Twitter.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2OESy4IWQoM"
      },
      "source": [
        "# Sentiment Analysis of Movie Opinion in Twitter\n",
        "\n",
        "**Reference:**\n",
        "https://github.com/rizalespe/Dataset-Sentimen-Analisis-Bahasa-Indonesia/blob/master/dataset_tweet_sentiment_opini_film.csv\n",
        "\n",
        "\n",
        "**The algorithms:**\n",
        "Multinomial NB(Naive Bayes)\n",
        "\n",
        "**Dataset:** \n",
        "dataset_tweet_sentiment_opini_film.csv\n",
        "\n",
        "The dataset contains 200 tweets, negative sentiment and positive sentiment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upVzK26QWQrA"
      },
      "source": [
        "# **Training Step**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGijVKUAovSI"
      },
      "source": [
        "### Read the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDV3B7l4WQrB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "f16c6e48-7ce5-434c-b228-c8d2b8c628dd"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"/content/dataset_tweet_sentiment_opini_film.csv\", nrows=30000)\n",
        "df.head()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>Text_Tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>negative</td>\n",
              "      <td>Jelek filmnya... apalagi si ernest gak mutu bg...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>negative</td>\n",
              "      <td>Film king Arthur ini film paling jelek dari se...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>negative</td>\n",
              "      <td>@beexkuanlin Sepanjang film gwa berkata kasar ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>negative</td>\n",
              "      <td>Ane ga suka fast and furious..menurutku kok je...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>negative</td>\n",
              "      <td>@baekhyun36 kan gua ga tau film nya, lu bilang...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Id Sentiment                                         Text_Tweet\n",
              "0   1  negative  Jelek filmnya... apalagi si ernest gak mutu bg...\n",
              "1   2  negative  Film king Arthur ini film paling jelek dari se...\n",
              "2   3  negative  @beexkuanlin Sepanjang film gwa berkata kasar ...\n",
              "3   4  negative  Ane ga suka fast and furious..menurutku kok je...\n",
              "4   5  negative  @baekhyun36 kan gua ga tau film nya, lu bilang..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8o2bzNm0WQrX"
      },
      "source": [
        "The columns:\n",
        "\n",
        "*   `polarity` column is whether the tweet is s positive or not.\n",
        "*   `text` column is the text of the tweet..\n",
        "\n",
        "\n",
        "How many rows?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "od6kaWswWQrY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5685e63-fa3a-44e7-dfd7-c5e1d469a029"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(200, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIfKjv4sWQru"
      },
      "source": [
        "How many **positive** and **negative** tweets?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "csktyEZBWQrw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af558e02-cb66-4e77-ae40-34a4606e89fa"
      },
      "source": [
        "df.Sentiment.value_counts()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "negative    100\n",
              "positive    100\n",
              "Name: Sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2H38c6muWQsK"
      },
      "source": [
        "## Train the algorithms\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2x-9dpkkWQsM"
      },
      "source": [
        "### Vectorize the tweets\n",
        "\n",
        "Create a `TfidfVectorizer` and use it to vectorize the tweets. \n",
        "Use `max_features` to take a selection of terms (1000) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnIKKpTUWQsQ"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5OjSw95DWQsl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        },
        "outputId": "749c78fb-839e-499e-dd77-1b48d4576f89"
      },
      "source": [
        "vectorizer = TfidfVectorizer(max_features=1000)\n",
        "vectors = vectorizer.fit_transform(df.Text_Tweet)\n",
        "words_df = pd.DataFrame(vectors.toarray(), columns=vectorizer.get_feature_names())\n",
        "words_df.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>000</th>\n",
              "      <th>10</th>\n",
              "      <th>13</th>\n",
              "      <th>13szi5lbc</th>\n",
              "      <th>15</th>\n",
              "      <th>18</th>\n",
              "      <th>1982</th>\n",
              "      <th>1uxomgqjs</th>\n",
              "      <th>20</th>\n",
              "      <th>2010</th>\n",
              "      <th>2017</th>\n",
              "      <th>207</th>\n",
              "      <th>21theguysquiz</th>\n",
              "      <th>22</th>\n",
              "      <th>2o2irpy</th>\n",
              "      <th>30</th>\n",
              "      <th>41</th>\n",
              "      <th>46i52na21l</th>\n",
              "      <th>4_oaoo</th>\n",
              "      <th>637</th>\n",
              "      <th>690</th>\n",
              "      <th>6tqqdgglj</th>\n",
              "      <th>90</th>\n",
              "      <th>95</th>\n",
              "      <th>abis</th>\n",
              "      <th>abiss</th>\n",
              "      <th>acclaim</th>\n",
              "      <th>actingnya</th>\n",
              "      <th>action</th>\n",
              "      <th>ada</th>\n",
              "      <th>adalah</th>\n",
              "      <th>adanya</th>\n",
              "      <th>adaptasi</th>\n",
              "      <th>adegan</th>\n",
              "      <th>adinia</th>\n",
              "      <th>aduh</th>\n",
              "      <th>aduk</th>\n",
              "      <th>after</th>\n",
              "      <th>agak</th>\n",
              "      <th>agama</th>\n",
              "      <th>...</th>\n",
              "      <th>uda</th>\n",
              "      <th>udah</th>\n",
              "      <th>udh</th>\n",
              "      <th>ujian</th>\n",
              "      <th>ulang</th>\n",
              "      <th>umur</th>\n",
              "      <th>unaazizah</th>\n",
              "      <th>unlocked</th>\n",
              "      <th>unsur</th>\n",
              "      <th>untuk</th>\n",
              "      <th>us</th>\n",
              "      <th>utk</th>\n",
              "      <th>video</th>\n",
              "      <th>visual</th>\n",
              "      <th>vlog</th>\n",
              "      <th>wajib</th>\n",
              "      <th>waktu</th>\n",
              "      <th>walau</th>\n",
              "      <th>warganet</th>\n",
              "      <th>watch</th>\n",
              "      <th>waw</th>\n",
              "      <th>weekend</th>\n",
              "      <th>weird</th>\n",
              "      <th>what</th>\n",
              "      <th>wib</th>\n",
              "      <th>wkwk</th>\n",
              "      <th>woman</th>\n",
              "      <th>wonder</th>\n",
              "      <th>worth</th>\n",
              "      <th>ya</th>\n",
              "      <th>yah</th>\n",
              "      <th>yakin</th>\n",
              "      <th>yang</th>\n",
              "      <th>yanskii</th>\n",
              "      <th>yaoi</th>\n",
              "      <th>yg</th>\n",
              "      <th>you</th>\n",
              "      <th>youtu</th>\n",
              "      <th>youtube</th>\n",
              "      <th>ziarah</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.393599</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.238215</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.241932</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 1000 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   000   10   13  13szi5lbc   15  ...   yg  you  youtu  youtube  ziarah\n",
              "0  0.0  0.0  0.0        0.0  0.0  ...  0.0  0.0    0.0      0.0     0.0\n",
              "1  0.0  0.0  0.0        0.0  0.0  ...  0.0  0.0    0.0      0.0     0.0\n",
              "2  0.0  0.0  0.0        0.0  0.0  ...  0.0  0.0    0.0      0.0     0.0\n",
              "3  0.0  0.0  0.0        0.0  0.0  ...  0.0  0.0    0.0      0.0     0.0\n",
              "4  0.0  0.0  0.0        0.0  0.0  ...  0.0  0.0    0.0      0.0     0.0\n",
              "\n",
              "[5 rows x 1000 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IaNSaJXxWQs5"
      },
      "source": [
        "### Setting the variables\n",
        "\n",
        "There are two variables: `X` and `y`.\n",
        "\n",
        "`X` = **features**\n",
        "\n",
        "`y` = **labels**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXsi0nWKWQs5"
      },
      "source": [
        "X = words_df\n",
        "y = df.Sentiment"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvcDvK5QWQtG"
      },
      "source": [
        "# **The algorithms:**\n",
        "\n",
        "1.   Logistic Regression\n",
        "2.   Random Forest Classifier\n",
        "3.   Linear SVM\n",
        "4.   Multinomial NB\n",
        "\n",
        "\n",
        "**You can pick just ONE or ALL OF THEM.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcK7bVXJWQtH"
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.naive_bayes import MultinomialNB"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tuFTkYb7WQtI"
      },
      "source": [
        "# **Training the algorithms**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0x0SOncjm9c"
      },
      "source": [
        "**Logistic Regression**\n",
        "\n",
        "- C: float, default = 1.0\n",
        "  - Inverse of regularization strength; must be a positive float. \n",
        "  - Smaller values specify stronger regularization.\n",
        "\n",
        "- solver = {‘newton-cg’, ‘lbfgs’, ‘liblinear’, ‘sag’, ‘saga’}, default = ’lbfgs’\n",
        "  - Algorithm to use in the optimization problem.\n",
        "  - For small datasets, ‘liblinear’ is a good choice, whereas ‘sag’ and ‘saga’ are faster for large ones.\n",
        "  - For multiclass problems, only ‘newton-cg’, ‘sag’, ‘saga’ and ‘lbfgs’ handle multinomial loss; ‘liblinear’ is limited to one-versus-rest schemes.\n",
        "  - ‘newton-cg’, ‘lbfgs’, ‘sag’ and ‘saga’ handle L2 or no penalty\n",
        "  - ‘liblinear’ and ‘saga’ also handle L1 penalty\n",
        "  - ‘saga’ also supports ‘elasticnet’ penalty\n",
        "  - ‘liblinear’ does not support setting penalty='none'\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOFHx7DOWQtI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e100a14-afdd-4efc-9646-29f9a5e00d5a"
      },
      "source": [
        "%%time\n",
        "# Create and train a logistic regression\n",
        "logreg = LogisticRegression(C=1e9, solver='lbfgs', max_iter=1000)\n",
        "logreg.fit(X, y)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 31.1 ms, sys: 7.02 ms, total: 38.1 ms\n",
            "Wall time: 27 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kL9Opu-Bkw4T"
      },
      "source": [
        "**Random Forest Classifier**\n",
        "\n",
        "- n_estimators: int, default = 100\n",
        "  - The number of trees in the forest."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3g02RfpWQtL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb90e93a-b406-4f1e-d71b-020fd14e2f80"
      },
      "source": [
        "%%time\n",
        "# Create and train a random forest classifier\n",
        "forest = RandomForestClassifier(n_estimators=50)\n",
        "forest.fit(X, y)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 142 ms, sys: 71.9 ms, total: 214 ms\n",
            "Wall time: 150 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FVZPKn2laZz"
      },
      "source": [
        "**Linear SVC**\n",
        "\n",
        "LinearSVC is another (faster) implementation of **Support Vector Classification** for the case of a **linear kernel**. \n",
        "\n",
        "Note that **LinearSVC** does not accept parameter kernel, as this is assumed to be linear."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Whua8HQaWQtO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3516751f-9cc2-40d6-fae8-c5c3445c7cd0"
      },
      "source": [
        "%%time\n",
        "# Create and train a linear support vector classifier (LinearSVC)\n",
        "svc = LinearSVC()\n",
        "svc.fit(X, y)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 5.75 ms, sys: 141 µs, total: 5.89 ms\n",
            "Wall time: 5.61 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QB-WsNhNmauu"
      },
      "source": [
        "**Multinomial NB**\n",
        "\n",
        "MultinomialNB implements the **naive Bayes algorithm** for multinomially distributed data, and is one of the two classic naive Bayes variants used in text classification (*where the data are typically represented as word vector counts, although tf-idf vectors are also known to work well in practice*)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cFI7uI8WQtR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88049f14-753b-4409-e0c8-5b1c08c294a6"
      },
      "source": [
        "%%time\n",
        "# Create and train a multinomial naive bayes classifier (MultinomialNB)\n",
        "bayes = MultinomialNB()\n",
        "bayes.fit(X, y)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 6.1 ms, sys: 6.02 ms, total: 12.1 ms\n",
            "Wall time: 12.2 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0dC4OBuWQtS"
      },
      "source": [
        "# Discussion 1\n",
        "\n",
        "How much faster were an algorithm compared to others?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3bIGp45WQtT"
      },
      "source": [
        "## Use the models\n",
        "\n",
        "We will use the model to predict whether the tweet is positive or negative.\n",
        "\n",
        "### Testing Data\n",
        "\n",
        "**You can add the testing data below.** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5eTOxO5WQtU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "outputId": "569c25b3-72a8-408b-81bf-37e904d04412"
      },
      "source": [
        "# Create some test data\n",
        "\n",
        "pd.set_option(\"display.max_colwidth\", 200)\n",
        "\n",
        "datatest = pd.DataFrame({'content': [\n",
        "    \"Jelek banget filmnya\",\n",
        "    \"Ini jadi film kesukaan\",\n",
        "    \"filmnya bagus banget\",\n",
        "    \"kecewa sama filmnya\",\n",
        "    \"bosen nonton filmnya\",\n",
        "    \"filmnya keren\",\n",
        "    \"menarik sih buat ditonton\",\n",
        "    \"Seru banget filmnya\",\n",
        "    \"Recommended buat ditonton\",\n",
        "    \"Film ini wajib ditonton\",\n",
        "]})\n",
        "datatest"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Jelek banget filmnya</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Ini jadi film kesukaan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>filmnya bagus banget</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>kecewa sama filmnya</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>bosen nonton filmnya</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>filmnya keren</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>menarik sih buat ditonton</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Seru banget filmnya</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Recommended buat ditonton</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Film ini wajib ditonton</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     content\n",
              "0       Jelek banget filmnya\n",
              "1     Ini jadi film kesukaan\n",
              "2       filmnya bagus banget\n",
              "3        kecewa sama filmnya\n",
              "4       bosen nonton filmnya\n",
              "5              filmnya keren\n",
              "6  menarik sih buat ditonton\n",
              "7        Seru banget filmnya\n",
              "8  Recommended buat ditonton\n",
              "9    Film ini wajib ditonton"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5RjU_IHWQtX"
      },
      "source": [
        "\n",
        "\n",
        "First we need to **vectorizer** the sentences into numbers, so the algorithm can understand them.\n",
        "\n",
        "Our algorithm only knows **certain words.** \n",
        "Run `vectorizer.get_feature_names()` to show you the list of the words it knows."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3_hqSV2WQtY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "103f2a79-427d-491b-c221-1000407e84fb"
      },
      "source": [
        "print(vectorizer.get_feature_names())"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['000', '10', '13', '13szi5lbc', '15', '18', '1982', '1uxomgqjs', '20', '2010', '2017', '207', '21theguysquiz', '22', '2o2irpy', '30', '41', '46i52na21l', '4_oaoo', '637', '690', '6tqqdgglj', '90', '95', 'abis', 'abiss', 'acclaim', 'actingnya', 'action', 'ada', 'adalah', 'adanya', 'adaptasi', 'adegan', 'adinia', 'aduh', 'aduk', 'after', 'agak', 'agama', 'ah', 'air', 'aj', 'aja', 'ajaa', 'akan', 'akhir', 'akhirnya', 'akhrnya', 'akting', 'aktingnya', 'aktor', 'aktornya', 'aktrisnya', 'aku', 'ale', 'alfi', 'alien', 'alitalit_', 'alur', 'ama', 'amat', 'amazing', 'ambigu', 'amira', 'an', 'anak', 'ancur', 'and', 'anda', 'andibowooo', 'ane', 'aneh', 'anjlok', 'anya', 'apa', 'apa2', 'apalagi', 'april', 'arah', 'arthur', 'artinya', 'artis', 'asih', 'asik', 'askmenfess', 'asli', 'astagah', 'atas', 'auratmu', 'awal', 'awalnya', 'awisuryadi', 'baca', 'baekhyun36', 'bagi', 'bagian', 'bagus', 'bagussss', 'bahagia', 'bahas', 'bahasa', 'bahwa', 'baik', 'bajakan', 'bakal', 'balap2', 'bandung', 'bang', 'bangat', 'banget', 'bangettt', 'bangga', 'banggafilmindonesia', 'bangsa', 'bangt', 'banyak', 'bapaknya', 'bareng', 'baru', 'barusan', 'be', 'beda', 'beexkuanlin', 'begadang', 'begini', 'belajar', 'belang', 'belidanur', 'belom', 'belum', 'belun', 'bener', 'bener2', 'bentar', 'beragam', 'berakhir', 'beranjak', 'berapa', 'berat', 'berbudget', 'berdua', 'berekspektasi', 'berhasil', 'berikut', 'berjuang', 'berkali', 'berkali2', 'berkata', 'berkualitas', 'berlapis', 'bermutu', 'berpendapatan', 'berpengaruh', 'bersabar', 'bertambah', 'bewe_bw', 'bgt', 'biasa', 'biasanya', 'bikin', 'bikinnya', 'bilang', 'bioskop', 'bisa', 'bit', 'bkin', 'black', 'blg', 'blm', 'bloopernya', 'bluray', 'bngt', 'bnr2', 'bnyak', 'bodoh', 'boring', 'bosen', 'britney', 'bs', 'buat', 'bukan', 'buku', 'busuk', 'campur', 'cek', 'cenayangfilm', 'cerita', 'ceritanya', 'cinema21', 'cinta', 'co', 'coba', 'cocok', 'cowok', 'creatif', 'credit', 'creepy', 'critanya', 'critical', 'criticaleleven', 'cucumu', 'cukup', 'cuma', 'cuman', 'cut', 'dada', 'dah', 'dalam', 'dan', 'danur', 'danurmovie', 'dapat', 'dapatkan', 'dapet', 'dari', 'daripada', 'datar', 'daur', 'dear', 'deh', 'dengan', 'depresi', 'dewasa', 'dgn', 'dhikefact', 'di', 'dia', 'dia2', 'diadaptasi', 'diajak', 'dian', 'diangkat', 'diapresiasi', 'dibalik', 'dibanding', 'dibawah', 'dibuat', 'diduga', 'digarap', 'dihabisken', 'diharepin', 'dikit', 'diluar', 'dilupakan', 'dimana', 'dimension', 'dingertiin', 'dinikmati', 'dipertemukan', 'dipetik', 'diputar', 'diri', 'dirilis', 'disajikan', 'disebut', 'disimak', 'disini', 'ditakdirkan', 'ditampilkan', 'ditonton', 'ditugasi', 'ditunggu', 'divergent', 'dkk', 'dlm', 'dng', 'doang', 'dominasi', 'download', 'dpt', 'dr', 'dramatis', 'drastis', 'dri', 'dua', 'duh', 'duit', 'dulu', 'dungu', 'durasi', 'e9ubwutbqj', 'editingnya', 'edoifus8p5', 'eh', 'ekspektasi', 'ekspektasinya', 'ekspetasi', 'eleven', 'embel2', 'emg', 'emosi', 'emosional', 'enak', 'ending', 'endingnya', 'entah', 'epic', 'ernes', 'ernest', 'ernestprakasa', 'ever', 'expresi', 'factrica', 'faktanya', 'falsafah', 'fargo', 'fast', 'favorit', 'favorite', 'fb', 'feature', 'feel', 'fff', 'film', 'filmkan', 'filmkartini', 'filmnya', 'filmya', 'filmziarah', 'flm', 'for', 'furious', 'ga', 'gadapet', 'gading', 'gagal', 'gak', 'gamau', 'gambarnya', 'gampang', 'gapernah', 'gara', 'gausah', 'gede', 'gedung', 'gegara', 'generasi', 'gerakan', 'get', 'getout', 'getoutmovie', 'gila', 'gimana', 'gini', 'gitu', 'gk', 'goal', 'gokil', 'gold', 'good', 'greatbos', 'greget', 'gua', 'gue', 'gurunya', 'guys', 'gw', 'gwa', 'habis', 'haha', 'hal', 'hambar', 'hambarr', 'hancurin', 'hangout', 'hans', 'hansdavidian', 'hanungbramantyo', 'hape', 'harap', 'harapan', 'hari', 'harus', 'harusnya', 'haruuuu', 'hasil', 'hasilnya', 'hehehe', 'hehehehe', 'hemmmm', 'hezsl', 'hidung', 'hidup', 'homo', 'hoo', 'horor', 'horror', 'hrs', 'http', 'https', 'huehe', 'hufy', 'ikanatassa', 'ikut', 'image', 'imdb', 'indonesia', 'ini', 'insidious', 'inspiratifnya', 'instrospeksi', 'insyaallahsah', 'intern', 'intinya', 'ironis', 'isinya', 'island', 'itu', 'jadi', 'jadian', 'jadiin', 'jadinya', 'jalan', 'jam', 'jaman', 'jarang', 'jawa', 'jelas', 'jelek', 'jelekk', 'jenius', 'jenuh', 'jgn', 'jijik', 'jijk', 'jika', 'jikalau', 'jiwa', 'job', 'jordan', 'judulnya', 'juga', 'jumlah', 'justru', 'jxtmtj0fc2u', 'ka', 'kadang', 'kagum', 'kak', 'kalau', 'kalaupun', 'kali', 'kalian', 'kalimat', 'kalo', 'kamar', 'kamu', 'kan', 'kantinidhijabers', 'karakter', 'karena', 'karna', 'kartini', 'karya', 'kasar', 'kasian', 'kasih', 'kask', 'kata', 'katanya', 'kategori', 'kaulahtakdirkumembelamu', 'kawin', 'kaya', 'ke', 'kebanyakan', 'kebayang', 'kebebasan', 'kebenaran', 'kece', 'kecewa', 'kecewaa', 'kecil', 'keingat', 'kekakuan', 'kekeluargaannya', 'kekuatan', 'kelakuan', 'kelar', 'kelas', 'keliatan', 'kelihatan', 'kelinci', 'kelompoknya', 'keluar', 'keluarga', 'kemana', 'kemenangan', 'kemudian', 'kenapa', 'kentel', 'kenyataan', 'kepalaku', 'kereen', 'keren', 'keresahan', 'kern', 'kerugian', 'keseluruhan', 'kesempatan', 'kesetiaan', 'ketawa', 'ketika', 'ketimbang', 'kgn', 'king', 'kita', 'kok', 'krn', 'kuat', 'kurang', 'lagi', 'lah', 'lalu', 'layak', 'layar', 'lebih', 'legacypictures', 'liat', 'lo', 'loh', 'lokal', 'lu', 'lucu', 'ly', 'makin', 'malah', 'mas', 'masih', 'mati', 'mau', 'mbah', 'me', 'memang', 'membatalkan', 'membawakan', 'memberikan', 'membuat', 'membuka', 'memenuhi', 'memgecewakan', 'menangis', 'menarik', 'mengerti', 'menginspirasi', 'menit', 'menitikkan', 'menjadi', 'menjaga', 'menjual', 'menjunjung', 'menonton', 'menurut', 'menurutku', 'menyenangkan', 'menyesal', 'menyukai', 'merasa', 'mereka', 'merusak', 'mesir', 'meski', 'mewek', 'mikir', 'minggu', 'minim', 'miris', 'misteri', 'mkir', 'mmbiarkan', 'mnrt', 'moveon', 'movie', 'mrk', 'msh', 'mu', 'mulai', 'mummy', 'nah', 'nangis', 'ngehek', 'nggak', 'nih', 'nilai', 'nntn', 'nnton', 'nonton', 'nontonnya', 'norak', 'novel', 'novelnya', 'ntar', 'ntn', 'nunggu', 'nungguin', 'nya', 'nyaman', 'nyari', 'nyedot', 'nyesel', 'nysel', 'obsessed', 'ogah', 'oke', 'oleh', 'openingnya', 'orang', 'oscar', 'out', 'pada', 'padahal', 'paginya', 'paket', 'paling', 'pandang', 'pandji', 'panjang', 'pantas', 'papa', 'parah', 'pas', 'pasangan', 'pasaran', 'pasca', 'pasti', 'patut', 'pd', 'pdahl', 'pdhl', 'pecah', 'peele', 'peluk', 'pemain', 'pemainnya', 'pemamarannya', 'pembuatan', 'pemeran', 'pemikiran', 'pemirsa', 'penampilannya', 'penasaran', 'pendukung', 'pengen', 'pengerjaan', 'penggambaran', 'penghargaan', 'penguasa', 'penista', 'penonton', 'penontonnya', 'penting', 'penurunan', 'peran', 'perang', 'perangan', 'percaya', 'percintaan', 'percuma', 'perdananya', 'perempuan', 'permintaan', 'pernah', 'persahabatan', 'persahabatannya', 'pertama', 'pertamanya', 'pertanyaan', 'pertengahan', 'pesan', 'pesbukers', 'pesen', 'pgn', 'pikiran', 'pilihan', 'pkoknya', 'plg', 'plot', 'pokoknya', 'pokonya', 'ponco', 'post', 'potong', 'power', 'premisnya', 'prilly', 'prillybie', 'produksi', 'produser', 'proses', 'puas', 'pula', 'pun', 'punya', 'quote', 'radit', 'raditya', 'radityadika', 'ragu', 'rangers', 'rasa', 'rasanya', 'ratattote', 'ratingnya', 'recomended', 'recommended', 'rekomended', 'relevan', 'respect', 'retak', 'review', 'reza', 'ribet', 'rilis', 'ringan', 'riset', 'romance', 'romanharusbertahan', 'romantis', 'rompisrepost', 'rp', 'rt', 'rujukan', 'rumit', 'rusia', 'saat', 'sabar', 'sahabat', 'saja', 'sakit', 'salah', 'salut', 'sama', 'sama2', 'samakan', 'samar', 'sampah', 'sampai', 'sampe', 'sana', 'sangat', 'sastro', 'satu', 'satunya', 'say', 'saya', 'sayang', 'sayangnya', 'sblm', 'sbnrnya', 'scene', 'scene2', 'screensaversid', 'seakan', 'season', 'sebagus', 'sebelah', 'sebelahnya', 'sebelumnya', 'sebenarnya', 'sebenernya', 'sebnarnya', 'sebuah', 'sebut', 'secara', 'sederhana', 'sedih', 'sedihnya', 'sedikit', 'segala2', 'segini', 'sehingga', 'sejak', 'sejarah', 'sekali', 'sekalipun', 'sekarang', 'sekitar', 'seksi', 'selain', 'selalu', 'selama', 'selamat', 'selera', 'selesai', 'selliyamanto', 'seluruh', 'semalam', 'semoga', 'sempet', 'semua', 'semuanya', 'sendiri', 'seneng', 'sensor', 'sepanjang', 'seperti', 'sepertinya', 'seragam', 'serakah', 'serem', 'seriesnya', 'sering', 'serius', 'seriusan', 'seru', 'sesal', 'seseorang', 'sesuai', 'sesungguhny', 'setahun', 'setan', 'setelah', 'setiap', 'setidaknya', 'sex', 'si', 'sih', 'silakan', 'simple', 'singkat', 'sini', 'situ', 'skip', 'skrg', 'skull', 'slalu', 'slamat', 'sllu', 'sm', 'sma', 'smp', 'smpai', 'smpe', 'sndiri', 'soal', 'sok', 'sorayafilms', 'sorry', 'sosok', 'special', 'speechless', 'spektakuler', 'sperti', 'spicles', 'sri', 'stlh', 'sudah', 'sudahi', 'sudut', 'suka', 'sukses', 'sumpah', 'sungguh', 'sungguh2', 'susah', 'sutradaranya', 'sy', 'syahadat', 'syukur2', 'tadi', 'tahun', 'tak', 'takut', 'tangan', 'tanggal', 'tanpa', 'tapi', 'tau', 'tayang', 'team', 'teaser', 'tegang', 'teh', 'telah', 'telat', 'tema', 'teman', 'temen', 'tenang', 'tentang', 'terakhir', 'teramat', 'terasa', 'terbaik', 'terbang', 'terbaru', 'terbatas', 'terbayarkan', 'terbuka', 'tercatat', 'terimakasi', 'terkenal', 'terkesan', 'terlalu', 'terlaris', 'terllu', 'termasuk', 'termurah', 'terngiang2', 'ternyata', 'tersebut', 'tertarik', 'tertebak', 'tertidur', 'tertinggi', 'terus', 'tetap', 'tetep', 'thank', 'thanks', 'the', 'thebossbaby', 'themummy', 'therealdisastr', 'this', 'thn', 'thur', 'tiap', 'tidak', 'tidur', 'tiga', 'tiket', 'tim', 'tinggal', 'tinggi', 'tingkat', 'tipe', 'tjoy', 'tk', 'tkeek3evs9', 'tll', 'tmen', 'tmn2', 'tnx', 'to', 'today', 'toko', 'tokoh', 'tolong', 'tom', 'tonton', 'tontonlah', 'topkrzd0dz', 'totalitas', 'tp', 'trailer', 'tread', 'trjadi', 'trlalu', 'trsa', 'trust', 'ttg', 'tu', 'tua', 'tuhan', 'tujuannya', 'tunggu', 'tz', 'ucweb', 'uda', 'udah', 'udh', 'ujian', 'ulang', 'umur', 'unaazizah', 'unlocked', 'unsur', 'untuk', 'us', 'utk', 'video', 'visual', 'vlog', 'wajib', 'waktu', 'walau', 'warganet', 'watch', 'waw', 'weekend', 'weird', 'what', 'wib', 'wkwk', 'woman', 'wonder', 'worth', 'ya', 'yah', 'yakin', 'yang', 'yanskii', 'yaoi', 'yg', 'you', 'youtu', 'youtube', 'ziarah']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tpx_6TwXWQta"
      },
      "source": [
        "**Because we already have the list of words we know, we only want to count them.** So instead of `.fit_transform`, we just use `.transform`:\n",
        "\n",
        "```python\n",
        "datatest_vectors = vectorizer.transform(datatest.content)\n",
        "datatest_words_df = ......\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZo0qtPDWQta",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        },
        "outputId": "36c79e57-0dcd-4add-f9ef-8c6b3d2f02aa"
      },
      "source": [
        "# Put it through the vectoriser\n",
        "\n",
        "# transform, not fit_transform, because we already learned all our words\n",
        "datatest_vectors = vectorizer.transform(datatest.content)\n",
        "datatest_words_df = pd.DataFrame(datatest_vectors.toarray(), columns=vectorizer.get_feature_names())\n",
        "datatest_words_df.head()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>000</th>\n",
              "      <th>10</th>\n",
              "      <th>13</th>\n",
              "      <th>13szi5lbc</th>\n",
              "      <th>15</th>\n",
              "      <th>18</th>\n",
              "      <th>1982</th>\n",
              "      <th>1uxomgqjs</th>\n",
              "      <th>20</th>\n",
              "      <th>2010</th>\n",
              "      <th>2017</th>\n",
              "      <th>207</th>\n",
              "      <th>21theguysquiz</th>\n",
              "      <th>22</th>\n",
              "      <th>2o2irpy</th>\n",
              "      <th>30</th>\n",
              "      <th>41</th>\n",
              "      <th>46i52na21l</th>\n",
              "      <th>4_oaoo</th>\n",
              "      <th>637</th>\n",
              "      <th>690</th>\n",
              "      <th>6tqqdgglj</th>\n",
              "      <th>90</th>\n",
              "      <th>95</th>\n",
              "      <th>abis</th>\n",
              "      <th>abiss</th>\n",
              "      <th>acclaim</th>\n",
              "      <th>actingnya</th>\n",
              "      <th>action</th>\n",
              "      <th>ada</th>\n",
              "      <th>adalah</th>\n",
              "      <th>adanya</th>\n",
              "      <th>adaptasi</th>\n",
              "      <th>adegan</th>\n",
              "      <th>adinia</th>\n",
              "      <th>aduh</th>\n",
              "      <th>aduk</th>\n",
              "      <th>after</th>\n",
              "      <th>agak</th>\n",
              "      <th>agama</th>\n",
              "      <th>...</th>\n",
              "      <th>uda</th>\n",
              "      <th>udah</th>\n",
              "      <th>udh</th>\n",
              "      <th>ujian</th>\n",
              "      <th>ulang</th>\n",
              "      <th>umur</th>\n",
              "      <th>unaazizah</th>\n",
              "      <th>unlocked</th>\n",
              "      <th>unsur</th>\n",
              "      <th>untuk</th>\n",
              "      <th>us</th>\n",
              "      <th>utk</th>\n",
              "      <th>video</th>\n",
              "      <th>visual</th>\n",
              "      <th>vlog</th>\n",
              "      <th>wajib</th>\n",
              "      <th>waktu</th>\n",
              "      <th>walau</th>\n",
              "      <th>warganet</th>\n",
              "      <th>watch</th>\n",
              "      <th>waw</th>\n",
              "      <th>weekend</th>\n",
              "      <th>weird</th>\n",
              "      <th>what</th>\n",
              "      <th>wib</th>\n",
              "      <th>wkwk</th>\n",
              "      <th>woman</th>\n",
              "      <th>wonder</th>\n",
              "      <th>worth</th>\n",
              "      <th>ya</th>\n",
              "      <th>yah</th>\n",
              "      <th>yakin</th>\n",
              "      <th>yang</th>\n",
              "      <th>yanskii</th>\n",
              "      <th>yaoi</th>\n",
              "      <th>yg</th>\n",
              "      <th>you</th>\n",
              "      <th>youtu</th>\n",
              "      <th>youtube</th>\n",
              "      <th>ziarah</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 1000 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   000   10   13  13szi5lbc   15   18  ...  yaoi   yg  you  youtu  youtube  ziarah\n",
              "0  0.0  0.0  0.0        0.0  0.0  0.0  ...   0.0  0.0  0.0    0.0      0.0     0.0\n",
              "1  0.0  0.0  0.0        0.0  0.0  0.0  ...   0.0  0.0  0.0    0.0      0.0     0.0\n",
              "2  0.0  0.0  0.0        0.0  0.0  0.0  ...   0.0  0.0  0.0    0.0      0.0     0.0\n",
              "3  0.0  0.0  0.0        0.0  0.0  0.0  ...   0.0  0.0  0.0    0.0      0.0     0.0\n",
              "4  0.0  0.0  0.0        0.0  0.0  0.0  ...   0.0  0.0  0.0    0.0      0.0     0.0\n",
              "\n",
              "[5 rows x 1000 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HrDQfcghWQtd"
      },
      "source": [
        "Confirm `datatest_words_df`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYX_42wwWQtg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3eedfb6f-bd22-4140-ffda-7c32e5a10222"
      },
      "source": [
        "datatest_words_df.shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, 1000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpx_0hlcWQtv"
      },
      "source": [
        "# **Predicting the models**\n",
        "\n",
        "\n",
        "We use `.predict` to predict class labels for each sentence and it will give a `0` (*negative*) or a `1` (*positive*) class:\n",
        "\n",
        "```python\n",
        "datatest['pred_logreg'] = logreg.predict(datatest_words_df)\n",
        "```\n",
        "\n",
        "We use `.predict_proba` to estimate the probability of the prediction.\n",
        "\n",
        "The returned estimates for all classes are ordered by the label of classes:\n",
        "\n",
        "\n",
        "```python\n",
        "datatest['pred_logreg_prob'] = linreg.predict_proba(datatest_words_df)[:,1]\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUJgJfQ_WQtw"
      },
      "source": [
        "# Predict using all our models. \n",
        "\n",
        "# Logistic Regression predictions + probabilities\n",
        "datatest['pred_logreg'] = logreg.predict(datatest_words_df)\n",
        "datatest['pred_logreg_proba'] = logreg.predict_proba(datatest_words_df)[:,1]\n",
        "\n",
        "# Random forest predictions + probabilities\n",
        "datatest['pred_forest'] = forest.predict(datatest_words_df)\n",
        "datatest['pred_forest_proba'] = forest.predict_proba(datatest_words_df)[:,1]\n",
        "\n",
        "# SVC predictions\n",
        "datatest['pred_svc'] = svc.predict(datatest_words_df)\n",
        "\n",
        "# Bayes predictions + probabilities\n",
        "datatest['pred_bayes'] = bayes.predict(datatest_words_df)\n",
        "datatest['pred_bayes_proba'] = bayes.predict_proba(datatest_words_df)[:,1]"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhERTSM_WQt9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 524
        },
        "outputId": "7cc29549-8894-45e9-c4d7-4b8fb2e8797f"
      },
      "source": [
        "datatest"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "      <th>pred_logreg</th>\n",
              "      <th>pred_logreg_proba</th>\n",
              "      <th>pred_forest</th>\n",
              "      <th>pred_forest_proba</th>\n",
              "      <th>pred_svc</th>\n",
              "      <th>pred_bayes</th>\n",
              "      <th>pred_bayes_proba</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Jelek banget filmnya</td>\n",
              "      <td>negative</td>\n",
              "      <td>6.512380e-06</td>\n",
              "      <td>negative</td>\n",
              "      <td>0.32</td>\n",
              "      <td>negative</td>\n",
              "      <td>negative</td>\n",
              "      <td>0.343761</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Ini jadi film kesukaan</td>\n",
              "      <td>negative</td>\n",
              "      <td>5.740527e-09</td>\n",
              "      <td>negative</td>\n",
              "      <td>0.08</td>\n",
              "      <td>negative</td>\n",
              "      <td>negative</td>\n",
              "      <td>0.343915</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>filmnya bagus banget</td>\n",
              "      <td>positive</td>\n",
              "      <td>9.999976e-01</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.60</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.646660</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>kecewa sama filmnya</td>\n",
              "      <td>negative</td>\n",
              "      <td>3.399591e-12</td>\n",
              "      <td>negative</td>\n",
              "      <td>0.28</td>\n",
              "      <td>negative</td>\n",
              "      <td>negative</td>\n",
              "      <td>0.240218</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>bosen nonton filmnya</td>\n",
              "      <td>positive</td>\n",
              "      <td>9.835608e-01</td>\n",
              "      <td>negative</td>\n",
              "      <td>0.48</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.585866</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>filmnya keren</td>\n",
              "      <td>positive</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.88</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.768228</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>menarik sih buat ditonton</td>\n",
              "      <td>positive</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.58</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.742361</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Seru banget filmnya</td>\n",
              "      <td>positive</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.56</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.705564</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Recommended buat ditonton</td>\n",
              "      <td>positive</td>\n",
              "      <td>9.999994e-01</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.54</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.743204</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Film ini wajib ditonton</td>\n",
              "      <td>positive</td>\n",
              "      <td>9.998311e-01</td>\n",
              "      <td>negative</td>\n",
              "      <td>0.36</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.726947</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     content pred_logreg  ...  pred_bayes pred_bayes_proba\n",
              "0       Jelek banget filmnya    negative  ...    negative         0.343761\n",
              "1     Ini jadi film kesukaan    negative  ...    negative         0.343915\n",
              "2       filmnya bagus banget    positive  ...    positive         0.646660\n",
              "3        kecewa sama filmnya    negative  ...    negative         0.240218\n",
              "4       bosen nonton filmnya    positive  ...    positive         0.585866\n",
              "5              filmnya keren    positive  ...    positive         0.768228\n",
              "6  menarik sih buat ditonton    positive  ...    positive         0.742361\n",
              "7        Seru banget filmnya    positive  ...    positive         0.705564\n",
              "8  Recommended buat ditonton    positive  ...    positive         0.743204\n",
              "9    Film ini wajib ditonton    positive  ...    positive         0.726947\n",
              "\n",
              "[10 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eUqM-23cWQuA"
      },
      "source": [
        "# Discussion 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YIF17XNVWQuB"
      },
      "source": [
        "\n",
        "1.   What do the numbers mean? What's the difference between 0, 1, or 0,5?\n",
        "2.   Were there any sentences where the classifiers seemed to disagree about? Give your analysis!\n",
        "3.   What's the difference between using a (0 and 1) in sentiment analysis compared to a range of 0 - 1? When might you use one compared to another?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jrmzLKXsWQuB"
      },
      "source": [
        "# **Testing our models**\n",
        "\n",
        "Which model performs the best??"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VguiqYowWQuC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "7d38c168-f2ae-45b7-8c97-9d8b075bb025"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>Text_Tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>negative</td>\n",
              "      <td>Jelek filmnya... apalagi si ernest gak mutu bgt actingnya... film sampah</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>negative</td>\n",
              "      <td>Film king Arthur ini film paling jelek dari seluruh cerita King Arthur</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>negative</td>\n",
              "      <td>@beexkuanlin Sepanjang film gwa berkata kasar terus pada bapaknya</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>negative</td>\n",
              "      <td>Ane ga suka fast and furious..menurutku kok jelek ya tu film</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>negative</td>\n",
              "      <td>@baekhyun36 kan gua ga tau film nya, lu bilang perang perangan/? Perang\"an disebut ama rp yaoi jadi ambigu :v</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Id  ...                                                                                                     Text_Tweet\n",
              "0   1  ...                                       Jelek filmnya... apalagi si ernest gak mutu bgt actingnya... film sampah\n",
              "1   2  ...                                        Film king Arthur ini film paling jelek dari seluruh cerita King Arthur \n",
              "2   3  ...                                              @beexkuanlin Sepanjang film gwa berkata kasar terus pada bapaknya\n",
              "3   4  ...                                                   Ane ga suka fast and furious..menurutku kok jelek ya tu film\n",
              "4   5  ...  @baekhyun36 kan gua ga tau film nya, lu bilang perang perangan/? Perang\"an disebut ama rp yaoi jadi ambigu :v\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQFa5fS6WQuG"
      },
      "source": [
        "Our  dataframe is a list of many tweets. We turned this into `X` - vectorized words - and `y` - whether the tweet is negative or positive.\n",
        "\n",
        "Before we used `.fit(X, y)` to train on all of our data. \n",
        "\n",
        "Instead, **we can test our models** by doing a test/train split and see if the predictions match the actual labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZezgb-GWQuG"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3dbJS6uWQuI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0655257f-0995-4074-e88c-e03c3d8b3f1a"
      },
      "source": [
        "%%time\n",
        "\n",
        "print(\"Training logistic regression\")\n",
        "logreg.fit(X_train, y_train)\n",
        "\n",
        "print(\"Training random forest\")\n",
        "forest.fit(X_train, y_train)\n",
        "\n",
        "print(\"Training SVC\")\n",
        "svc.fit(X_train, y_train)\n",
        "\n",
        "print(\"Training Naive Bayes\")\n",
        "bayes.fit(X_train, y_train)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training logistic regression\n",
            "Training random forest\n",
            "Training SVC\n",
            "Training Naive Bayes\n",
            "CPU times: user 180 ms, sys: 96.6 ms, total: 277 ms\n",
            "Wall time: 163 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6fmBf0A3WQuJ"
      },
      "source": [
        "### Confusion matrices\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xreZ5f__WQuK"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score \n",
        "from sklearn.metrics import classification_report "
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0JryApBWQuN"
      },
      "source": [
        "#### Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRSepgjzWQuN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "6770b70d-2a19-400f-84d2-a51a166246c6"
      },
      "source": [
        "y_true1 = y_test\n",
        "y_pred1 = logreg.predict(X_test)\n",
        "matrix1 = confusion_matrix(y_true1, y_pred1)\n",
        "\n",
        "label_names = pd.Series(['negative', 'positive'])\n",
        "pd.DataFrame(matrix1,\n",
        "     columns='Predicted ' + label_names,\n",
        "     index='Is ' + label_names)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Predicted negative</th>\n",
              "      <th>Predicted positive</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Is negative</th>\n",
              "      <td>18</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Is positive</th>\n",
              "      <td>2</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             Predicted negative  Predicted positive\n",
              "Is negative                  18                   2\n",
              "Is positive                   2                  18"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fBpYencWQuO"
      },
      "source": [
        "#### Random forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "df1s1LUYWQuP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "79cbdf3b-adce-4ab0-94a1-2f8410a1cbc5"
      },
      "source": [
        "y_true2 = y_test\n",
        "y_pred2 = forest.predict(X_test)\n",
        "matrix2 = confusion_matrix(y_true2, y_pred2)\n",
        "\n",
        "label_names = pd.Series(['negative', 'positive'])\n",
        "pd.DataFrame(matrix2,\n",
        "     columns='Predicted ' + label_names,\n",
        "     index='Is ' + label_names)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Predicted negative</th>\n",
              "      <th>Predicted positive</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Is negative</th>\n",
              "      <td>16</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Is positive</th>\n",
              "      <td>3</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             Predicted negative  Predicted positive\n",
              "Is negative                  16                   4\n",
              "Is positive                   3                  17"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fkGsFbfiWQuR"
      },
      "source": [
        "#### SVC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_8lha9GWQuR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "0789e79a-1920-4faf-b9a7-58b033283749"
      },
      "source": [
        "y_true3 = y_test\n",
        "y_pred3 = svc.predict(X_test)\n",
        "matrix3 = confusion_matrix(y_true3, y_pred3)\n",
        "\n",
        "label_names = pd.Series(['negative', 'positive'])\n",
        "pd.DataFrame(matrix3,\n",
        "     columns='Predicted ' + label_names,\n",
        "     index='Is ' + label_names)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Predicted negative</th>\n",
              "      <th>Predicted positive</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Is negative</th>\n",
              "      <td>18</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Is positive</th>\n",
              "      <td>2</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             Predicted negative  Predicted positive\n",
              "Is negative                  18                   2\n",
              "Is positive                   2                  18"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lWlWacMWQus"
      },
      "source": [
        "#### Multinomial Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Clq5DxlBWQut",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "0bfc171c-bd6a-4c84-84d3-6e207bd940c6"
      },
      "source": [
        "y_true4 = y_test\n",
        "y_pred4 = bayes.predict(X_test)\n",
        "matrix4 = confusion_matrix(y_true4, y_pred4)\n",
        "\n",
        "label_names = pd.Series(['negative', 'positive'])\n",
        "pd.DataFrame(matrix4,\n",
        "     columns='Predicted ' + label_names,\n",
        "     index='Is ' + label_names)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Predicted negative</th>\n",
              "      <th>Predicted positive</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Is negative</th>\n",
              "      <td>19</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Is positive</th>\n",
              "      <td>2</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             Predicted negative  Predicted positive\n",
              "Is negative                  19                   1\n",
              "Is positive                   2                  18"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mOjMPa_NWQuw"
      },
      "source": [
        "### Percentage-based confusion matrices\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "El7gYgbTWQuw"
      },
      "source": [
        "#### Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOczxDwKWQux",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "8eb4e7eb-04db-49ae-ef01-3bd1af4ad0c2"
      },
      "source": [
        "y_true1 = y_test\n",
        "y_pred1 = logreg.predict(X_test)\n",
        "matrix1 = confusion_matrix(y_true2, y_pred2)\n",
        "\n",
        "label_names = pd.Series(['negative', 'positive'])\n",
        "pd.DataFrame(matrix1,\n",
        "     columns='Predicted ' + label_names,\n",
        "     index='Is ' + label_names).div(matrix1.sum(axis=1), axis=0)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Predicted negative</th>\n",
              "      <th>Predicted positive</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Is negative</th>\n",
              "      <td>0.80</td>\n",
              "      <td>0.20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Is positive</th>\n",
              "      <td>0.15</td>\n",
              "      <td>0.85</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             Predicted negative  Predicted positive\n",
              "Is negative                0.80                0.20\n",
              "Is positive                0.15                0.85"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQWciZMFJcMc",
        "outputId": "375c1c26-4c9c-46bd-ef9f-c14d57804f84"
      },
      "source": [
        "print('Confusion Matrix :')\n",
        "print(matrix1) \n",
        "print('Accuracy Score :',accuracy_score(y_true1, y_pred1))\n",
        "print('Report : ')\n",
        "print(classification_report(y_true1, y_pred1))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix :\n",
            "[[16  4]\n",
            " [ 3 17]]\n",
            "Accuracy Score : 0.9\n",
            "Report : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.90      0.90      0.90        20\n",
            "    positive       0.90      0.90      0.90        20\n",
            "\n",
            "    accuracy                           0.90        40\n",
            "   macro avg       0.90      0.90      0.90        40\n",
            "weighted avg       0.90      0.90      0.90        40\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ng5GKtS9WQu3"
      },
      "source": [
        "#### Random forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UpAXbWeWQu3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "d7bf32da-9355-44be-c328-d8f9dcf667e7"
      },
      "source": [
        "y_true2 = y_test\n",
        "y_pred2 = forest.predict(X_test)\n",
        "matrix2 = confusion_matrix(y_true2, y_pred2)\n",
        "\n",
        "label_names = pd.Series(['negative', 'positive'])\n",
        "pd.DataFrame(matrix2,\n",
        "     columns='Predicted ' + label_names,\n",
        "     index='Is ' + label_names).div(matrix3.sum(axis=1), axis=0)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Predicted negative</th>\n",
              "      <th>Predicted positive</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Is negative</th>\n",
              "      <td>0.80</td>\n",
              "      <td>0.20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Is positive</th>\n",
              "      <td>0.15</td>\n",
              "      <td>0.85</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             Predicted negative  Predicted positive\n",
              "Is negative                0.80                0.20\n",
              "Is positive                0.15                0.85"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AihYBxadJ8Ju",
        "outputId": "7a39a96c-1346-437e-8627-adb8526be21b"
      },
      "source": [
        "print('Confusion Matrix :')\n",
        "print(matrix2) \n",
        "print('Accuracy Score :',accuracy_score(y_true2, y_pred2))\n",
        "print('Report : ')\n",
        "print(classification_report(y_true2, y_pred2))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix :\n",
            "[[16  4]\n",
            " [ 3 17]]\n",
            "Accuracy Score : 0.825\n",
            "Report : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.84      0.80      0.82        20\n",
            "    positive       0.81      0.85      0.83        20\n",
            "\n",
            "    accuracy                           0.82        40\n",
            "   macro avg       0.83      0.82      0.82        40\n",
            "weighted avg       0.83      0.82      0.82        40\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ihFVnsTqWQvC"
      },
      "source": [
        "#### SVC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqk4vAgGWQvD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "635c4dd0-3c12-471e-a524-d4a8f71777a8"
      },
      "source": [
        "y_true3 = y_test\n",
        "y_pred3 = svc.predict(X_test)\n",
        "matrix3 = confusion_matrix(y_true3, y_pred3)\n",
        "\n",
        "label_names = pd.Series(['negative', 'positive'])\n",
        "pd.DataFrame(matrix3,\n",
        "     columns='Predicted ' + label_names,\n",
        "     index='Is ' + label_names).div(matrix3.sum(axis=1), axis=0)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Predicted negative</th>\n",
              "      <th>Predicted positive</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Is negative</th>\n",
              "      <td>0.9</td>\n",
              "      <td>0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Is positive</th>\n",
              "      <td>0.1</td>\n",
              "      <td>0.9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             Predicted negative  Predicted positive\n",
              "Is negative                 0.9                 0.1\n",
              "Is positive                 0.1                 0.9"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UEz5WN_NKjKC",
        "outputId": "279fbeeb-fd3e-4574-cdfe-501b5309caf1"
      },
      "source": [
        "print('Confusion Matrix :')\n",
        "print(matrix3) \n",
        "print('Accuracy Score :',accuracy_score(y_true3, y_pred3))\n",
        "print('Report : ')\n",
        "print(classification_report(y_true3, y_pred3))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix :\n",
            "[[18  2]\n",
            " [ 2 18]]\n",
            "Accuracy Score : 0.9\n",
            "Report : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.90      0.90      0.90        20\n",
            "    positive       0.90      0.90      0.90        20\n",
            "\n",
            "    accuracy                           0.90        40\n",
            "   macro avg       0.90      0.90      0.90        40\n",
            "weighted avg       0.90      0.90      0.90        40\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LyCvYvMQWQvH"
      },
      "source": [
        "#### Multinomial Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vH14zuEmWQvI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "66dbe21d-883a-4b6c-e0e9-8e8b7650aecd"
      },
      "source": [
        "y_true4 = y_test\n",
        "y_pred4 = bayes.predict(X_test)\n",
        "matrix4 = confusion_matrix(y_true4, y_pred4)\n",
        "\n",
        "label_names = pd.Series(['negative', 'positive'])\n",
        "pd.DataFrame(matrix4,\n",
        "     columns='Predicted ' + label_names,\n",
        "     index='Is ' + label_names).div(matrix4.sum(axis=1), axis=0)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Predicted negative</th>\n",
              "      <th>Predicted positive</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Is negative</th>\n",
              "      <td>0.95</td>\n",
              "      <td>0.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Is positive</th>\n",
              "      <td>0.10</td>\n",
              "      <td>0.90</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             Predicted negative  Predicted positive\n",
              "Is negative                0.95                0.05\n",
              "Is positive                0.10                0.90"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CzrMCUReKpPx",
        "outputId": "96f5239a-19a3-4895-f106-d8c98269737c"
      },
      "source": [
        "print('Confusion Matrix :')\n",
        "print(matrix4) \n",
        "print('Accuracy Score :',accuracy_score(y_true4, y_pred4))\n",
        "print('Report : ')\n",
        "print(classification_report(y_true4, y_pred4))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix :\n",
            "[[19  1]\n",
            " [ 2 18]]\n",
            "Accuracy Score : 0.925\n",
            "Report : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.90      0.95      0.93        20\n",
            "    positive       0.95      0.90      0.92        20\n",
            "\n",
            "    accuracy                           0.93        40\n",
            "   macro avg       0.93      0.93      0.92        40\n",
            "weighted avg       0.93      0.93      0.92        40\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsCOoEMxWQvK"
      },
      "source": [
        "## Review\n",
        "\n",
        "- Step 1: use a **vectorizer** to convert the tweets into numbers a computer could understand.\n",
        "- Step 2: Training step to **build** the models \n",
        "- Step 3: split the dataset into **train** and **test** dataset\n",
        "- Step 4: Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yylPihUmWQvL"
      },
      "source": [
        "## Discussion [3]\n",
        "\n",
        "* Which models performed the best? Explain the big differences between them!\n",
        "* Do you think it's more important to be sensitive to negativity or positivity? Do we want more positive things incorrectly marked as negative, or more negative things marked as positive?\n",
        "* They all had very different training times. Which ones offer the best combination of performance?\n",
        "* What's good accuracy? Do you think 75% is good enough?\n",
        "* If there are 2 classifiers and both of them are 75% accurate, which is the best?"
      ]
    }
  ]
}